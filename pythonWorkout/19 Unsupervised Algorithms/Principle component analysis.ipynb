{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis\n",
    "- Dimensionality reduction technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the curse of dimensionality ?\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why do we need this techniques ?\n",
    "  - This technique is used for dimensionality reduction.\n",
    "  - When the number of features are high in the dataset, the model will be more generalized and they have to allocate weights to each of this features and compute again. This makes the process computationally heavy. So, it is necessary to perform feature engineering and principal component analysis to overcome the issues of curse of dimensionality. Increased number of features --> decreased accuracy --> increased computation power consumption --> learning from all the features could degrade the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ways to remove the curse of dimensionality \n",
    "   - Feature engineering and selection \n",
    "   - Dimensionality reduction technique\n",
    "     - Principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model and algorithms are used synonymously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why feature selection or dimensionality reduction \n",
    "  - To overcome the problem of curse of dimensionality reduction\n",
    "  - To enhance the performance of the model \n",
    "  - To visualize the data, as human can interpret the data in 3d at maximum however the dimensionality reduction techniques enable the user to visualize more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Why do we predominantly use correlation for determining the strength of relationship rather than covariance ?__\n",
    "   - Co-variance depends on its unit. For eg. In determining the relation between height and weight, the units are different. Height in cm, and weight in Kg. However the correlation has the standard deviation on its bottom for every feature, thus gives us unit less outcomes and quantified strength of relationship between variables\n",
    "  - Covariance ranges from positive infinity value to negative infinity value, thus quantifying and determining the relationship strength with co-variance could be misleading. Since the correlation ranges from -1 to 1, it enables the easy measurement.\n",
    "     - When correlation value lies nearer to -1 depicts the stronger negative correlation.\n",
    "     - When the correlation value lies nearer to +1 depicts the stronger positive correlation.\n",
    "     - When correlation values lies closer to 0 depicts minimum or no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __What do you mean by  univariate, bi-variate and multivariate analysis ? and why is it needed?__\n",
    "  - Univariate Analysis:\n",
    "    - Involves analyzing one variable (column) at a time.\n",
    "    - Focuses on understanding the distribution of the data, identifying outliers, assessing skewness, and examining for null values or other irregularities.\n",
    "    - Purpose: Provides insights into the central tendency, variability, and structure of a single variable, helping to understand its behavior independently.\n",
    "        - Example: Examining the distribution of \"Age\" in a dataset using histograms, boxplots, or summary statistics.\n",
    "  - Bivariate Analysis:\n",
    "    - Involves the relationship between two variables.\n",
    "    - Often focuses on independent and dependent variables in supervised learning tasks to explore their associations or dependencies.\n",
    "    - Tools like scatter plots, correlation coefficients, and hypothesis testing (e.g., t-tests) are commonly used.\n",
    "    - Purpose: Helps identify patterns, relationships, or trends between two variables and lays the foundation for predictive modeling.\n",
    "      - Example: Comparing \"Years of Experience\" (independent variable) and \"Salary\" (dependent variable) to study their relationship.\n",
    "  - Multivariate Analysis:\n",
    "      - Examines relationships among three or more variables simultaneously.\n",
    "      - Includes techniques like correlation matrices, covariance, principal component analysis (PCA), and regression models to understand complex relationships.\n",
    "      - Purpose: Provides deeper insights into data structure, uncovers hidden patterns, and helps in dimensionality reduction for complex datasets.\n",
    "        - Example: Studying how \"Age,\" \"Education Level,\" and \"Years of Experience\" together influence \"Salary.\"\n",
    "\n",
    "\n",
    "- __Why Is It Needed?__\n",
    "  - Univariate Analysis: Ensures data quality, identifies irregularities, and helps decide preprocessing steps like normalization or outlier handling.\n",
    "  - Bivariate Analysis: Reveals relationships and dependencies that guide feature selection and model building.\n",
    "  - Multivariate Analysis: Helps understand the interplay of multiple variables, aids in predictive analysis, and uncovers hidden patterns for better decision-making.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
